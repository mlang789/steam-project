=== GENERATION EVALUATION REPORT ===

Model Type:  SBERT
Input File:  /home/mathisdumont/dev/ENSAE/s1/ML_python/steam-project/reports/genai_inputs/prompt_batch_filled.csv
Model Path:  /home/mathisdumont/dev/ENSAE/s1/ML_python/steam-project/reports/models/judge_model_sbert.joblib
----------------------------------------

    method    n  compliance_rate  mean_pred_proba  length_ok_rate  mean_word_count
 finetuned 4422         0.875170         0.667332        0.810719       115.682497
engineered 1800         0.798333         0.649678        0.996667       121.552778
     naive 1800         0.843889         0.649496        0.995000       121.572222

----------------------------------------
Legend:
- compliance_rate: % of reviews matching the target sentiment (Pos/Neg)
